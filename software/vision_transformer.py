# -*- coding: utf-8 -*-
"""Vision_Transformer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qKtfzNE_sjn8Y3489lWsAekm-EEmHAxi
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
import random
import matplotlib.pyplot as plt

torch.__version__

torchvision.__version__

"""Set Up Device Agnostics"""

torch.cuda.is_available()

device = "cuda" if torch.cuda.is_available() else "cpu"
device

"""Set The Seed"""

torch.manual_seed(42)
torch.cuda.manual_seed(42)
random.seed(42)

"""Setting the Hyperparameters"""

BATCH_SIZE = 128
EPOCHS = 10
LEARNING_RATE = 3e-4
PATCH_SIZE = 4
NUM_CLASSES = 10
IMAGE_SIZE = 32
CHANNELS = 3
EMBED_DIM = 256
NUM_HEADS = 8
DEPTH = 6
MLP_DIM = 512
DROP_RATE = 0.1

"""Define Image Transformations"""

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5),(0.5))
])

"""Getting a Dataset

"""

train_dataset = datasets.CIFAR10(root="data",
                                  train = True,
                                 download = True,
                                 transform = transform)

test_dataset = datasets.CIFAR10(root = "data",
                                train = False,
                                download = True,
                                transform = transform)

train_dataset

test_dataset

len(test_dataset)

"""Converting our datasets into Dataloaders"""

train_loader = DataLoader(dataset=train_dataset,
                          batch_size =BATCH_SIZE,
                          shuffle = True)
test_loader = DataLoader(dataset=test_dataset,
                         batch_size = BATCH_SIZE,
                         shuffle = False)

print(f"Dataloader : {train_loader, test_loader}")
print(f"Length of Trainloader : {len(train_loader)} batches of {BATCH_SIZE}..")
print(f"Length of Testloader : {len(test_loader)} batches of {BATCH_SIZE}..")

"""BUILDING VISION TRANSFORMER MODEL FROM SCRATCH"""

class PatchEmbedding(nn.Module):
  def __init__ (self,
                img_size,
                patch_size,
                in_channels,
                emd_dim):
    super().__init__()
    self.patch_size = patch_size
    self.proj = nn.Conv2d(in_channels=in_channels,
                          out_channels=emd_dim,
                          kernel_size=patch_size,
                          stride=patch_size)
    num_patches = (img_size // patch_size) ** 2
    self.cls_token = nn.Parameter(torch.randn(1,1,emd_dim))
    self.pos_embed = nn.Parameter(torch.randn(1,1+num_patches,emd_dim))

  def forward(self,x: torch.Tensor):
   B = x.size(0)
   x = self.proj(x)
   x = x.flatten(2).transpose(1,2)
   cls_token = self.cls_token.expand(B,-1,-1)
   x = torch.cat((cls_token,x),dim=1)
   x = x + self.pos_embed
   return x

class MLP(nn.Module):
  def __init__(self,
               in_features,
               hidden_features,
               drop_rate):
    super().__init__()
    self.fc1 = nn.Linear(in_features=in_features,
                         out_features=hidden_features)
    self.dropout = nn.Dropout(p=drop_rate)
    self.fc2 = nn.Linear(in_features=hidden_features,
                         out_features=in_features)

  def forward(self,x):
    x = self.dropout(F.gelu(self.fc1(x)))
    x = self.dropout(self.fc2(x))
    return x

class TransformerEncoderLayer(nn.Module):
  def __init__(self,embed_dim,num_heads,mlp_dim,drop_rate):
    super().__init__()
    self.norm1 = nn.LayerNorm(embed_dim)
    self.attn = nn.MultiheadAttention(embed_dim,num_heads,dropout=drop_rate,batch_first=True)
    self.norm2 = nn.LayerNorm(embed_dim)
    self.mlp = MLP(embed_dim,mlp_dim,drop_rate)

  def forward(self,x):
    x = x + self.attn(self.norm1(x), self.norm1(x),self.norm1(x))[0]
    x = x + self.mlp(self.norm2(x))
    return x

class VisionTransformer(nn.Module):
  def __init__(self,img_size,patch_size,in_channels,num_classes,embed_dim,num_heads,depth,mlp_dim,drop_rate):
    super().__init__()
    self.patch_embed = PatchEmbedding(img_size,
                                      patch_size,
                                      in_channels,
                                      embed_dim)
    self.encoder = nn.Sequential(*[TransformerEncoderLayer(embed_dim,num_heads,mlp_dim,drop_rate)
    for _ in range(depth)])
    self.norm = nn.LayerNorm(embed_dim)
    self.head = nn.Linear(embed_dim,num_classes)

  def forward(self,x):
    x = self.patch_embed(x)
    x = self.encoder(x)
    x = self.norm(x)
    cls_token = x[:,0]
    return self.head(cls_token)

"""Instantiate Model"""

from IPython.core.display import Image
model = VisionTransformer(
    IMAGE_SIZE,
    PATCH_SIZE,
    CHANNELS,
    NUM_CLASSES,
    EMBED_DIM,
    NUM_HEADS,
    DEPTH,
    MLP_DIM,
    DROP_RATE
).to(device)

model

"""Defiinig a Loss Function and an Optimizer

"""

criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(params = model.parameters(), lr=LEARNING_RATE)

criterion

optimizer

"""Definig a Training Loop function

"""

def train(model, loader, optimizer, criterion):
  model.train()
  total_loss, correct = 0,0
  for x,y in loader:
    x, y = x.to(device), y.to(device)
    optimizer.zero_grad()
    out = model(x)
    loss = criterion(out,y)
    loss.backward()
    optimizer.step()

    total_loss += loss.item() * x.size(0)
    correct += (out.argmax(1) == y).sum().item()

  return total_loss / len(loader.dataset), correct / len(loader.dataset)

def evaluate(model, loader):
  model.eval()
  correct = 0
  with torch.inference_mode():
    for x,y in loader:
      x, y = x.to(device), y.to(device)
      out = model(x)
      correct += (out.argmax(dim=1) == y).sum().item()

  return correct / len(loader.dataset)

"""Training"""

from tqdm.auto import tqdm

train_accuracies = []
test_accuracies = []
for epoch in tqdm(range(EPOCHS)):
  train_loss, train_acc = train(model, train_loader, optimizer, criterion)
  test_acc = evaluate(model, test_loader)
  train_accuracies.append(train_acc)
  test_accuracies.append(test_acc)

  print(f"Epoch : {epoch+1}/{EPOCHS}..",
        f"Train Loss : {train_loss:.4f} | Train Acc : {train_acc*100:.2f}% | Test Acc : {test_acc*100:.2f}%")

train_accuracies

test_accuracies

"""Plot Accuracy"""

plt.plot(train_accuracies, label="Train Accuracy")
plt.plot(test_accuracies, label="Test Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Training and Test Accuracy")
plt.show()

import random

def predict_and_plot_grid(model,
                          dataset,
                          classes,
                          grid_size=3):
  model.eval()
  fig, axes = plt.subplots(grid_size, grid_size, figsize=(9,9))
  for i in range(grid_size):
    for j in range(grid_size):
      idx = random.randint(0, len(dataset)-1)
      img, true_label = dataset[idx]
      input_tensor = img.unsqueeze(dim=0).to(device)
      with torch.inference_mode():
        output = model(input_tensor)
        _ , predicted = torch.max(output.data, 1)
      img = img / 2 + 0.5 # Unnormalize the image
      npimg = img.cpu().numpy()
      axes[i,j].imshow(np.transpose(npimg, (1,2,0)))
      truth = classes[true_label] == classes[predicted.item()]
      if truth:
        color = 'g'
      else:
        color = 'r'

      axes[i,j].set_title(f"Truth: {classes[true_label]}\nPredicted: {classes[predicted.item()]}", fontsize = 10, c=color)
      axes[i,j].axis('off')
  plt.tight_layout()
  plt.show()

predict_and_plot_grid(model, test_dataset, classes=train_dataset.classes, grid_size=3)



